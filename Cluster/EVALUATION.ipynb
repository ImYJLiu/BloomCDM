{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85eef639-24e2-4b8b-bd17-586d3250a668",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tools/features_logits/lane_embedding_feats.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8054920e4156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./tools/features_logits/lane_embedding_feats.npy\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 导入数据，数据格式为（samples，）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDBSCAN_Cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 进行 DBSCAN聚类\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyj_env/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tools/features_logits/lane_embedding_feats.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glog as log\n",
    " \n",
    "from sklearn.cluster import DBSCAN  # 进行DBSCAN聚类\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score ,calinski_harabasz_score,davies_bouldin_score # 计算 轮廓系数，CH 指标，DBI \n",
    " \n",
    " \n",
    "# 定义一个进行DBSCAN的函数\n",
    "def DBSCAN_Cluster(embedding_image_feats):\n",
    "    \"\"\"\n",
    "    dbscan cluster\n",
    "    :param embedding_image_feats:  # 比如形状是（9434,4）表示9434个像素点\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=0.35, min_samples=600)\n",
    "    try:\n",
    "        features = StandardScaler().fit_transform(embedding_image_feats)  # 将特征进行归一化\n",
    "        db.fit(features)\n",
    "    except Exception as err:\n",
    "        log.error(err)   \n",
    "        ret = {\n",
    "            'origin_features': None,\n",
    "            'cluster_nums': 0,\n",
    "            'db_labels': None,\n",
    "            'cluster_center': None\n",
    "            }\n",
    "        return ret\n",
    " \n",
    "    db_labels = db.labels_                  # 获取聚类之后没一个样本的类别标签\n",
    "    unique_labels = np.unique(db_labels)    # 获取唯一的类别\n",
    " \n",
    "    num_clusters = len(unique_labels)\n",
    "    cluster_centers = db.components_\n",
    " \n",
    "    ret = {\n",
    "            'origin_features': features,      #(9434,4)\n",
    "            'cluster_nums': num_clusters,     # 5  它是一个标量，表示5类，包含背景\n",
    "            'db_labels': db_labels,           #(9434,)\n",
    "            'unique_labels': unique_labels,   #(5,)\n",
    "            'cluster_center': cluster_centers #(6425,4)\n",
    "        }\n",
    " \n",
    "    return ret\n",
    " \n",
    "# 画出聚类之后的结果\n",
    "def plot_dbscan_result(features,db_labels,unique_labels,num_clusters):\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "    for k, color in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "           color = 'k'  # 黑色的，这代表噪声点\n",
    " \n",
    "        index=np.where(db_labels==k)   #  获取每一个类别的索引位置\n",
    "        x=features[index]\n",
    " \n",
    "        plt.plot(x[:, 0], x[:, 1], 'o', markerfacecolor=color,markeredgecolor='k', markersize=6)\n",
    " \n",
    "    plt.title('Estimated number of clusters: %d' % num_clusters)\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "if __name__=='__main__':\n",
    "    embedding_features=np.load(\"./tools/features_logits/lane_embedding_feats.npy\")  # 导入数据，数据格式为（samples，）\n",
    " \n",
    "    ret=DBSCAN_Cluster(embedding_features)  # 进行 DBSCAN聚类\n",
    " \n",
    "    plot_dbscan_result(ret['origin_features'],ret['db_labels'],ret['unique_labels'],ret['cluster_nums']) # 展示聚类之后的结果\n",
    "     \n",
    "        \n",
    "        #silhouette_score (数据，生成的标签，指标)\n",
    "    \n",
    "    s1=silhouette_score(embedding_features, ret['db_labels'], metric='euclidean') # 计算轮廓系数\n",
    "    s2=calinski_harabasz_score(embedding_features,ret['db_labels']) # 计算CH score\n",
    "    s3=davies_bouldin_score(embedding_features,ret['db_labels'])    # 计算 DBI\n",
    " \n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(s3)\n",
    " \n",
    "'''运行结果为：\n",
    "0.7971864\n",
    "48375.80213812995\n",
    "0.8799878743935938\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00815e4e-6e05-4f4e-8fa6-f04d556c0622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: glog in /home/omnisky/anaconda3/envs/lyj_env/lib/python3.6/site-packages (0.3.1)\n",
      "Requirement already satisfied: python-gflags>=3.1 in /home/omnisky/anaconda3/envs/lyj_env/lib/python3.6/site-packages (from glog) (3.1.2)\n",
      "Requirement already satisfied: six in /home/omnisky/anaconda3/envs/lyj_env/lib/python3.6/site-packages (from glog) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install glog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca12b0-5331-4502-89b3-7c1e084ff499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
